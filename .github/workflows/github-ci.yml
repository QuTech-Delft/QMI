name: QMI Python CI runner

on:
  push:
    branches: [ "main" ]

env:
  # minimum pylint code quality score (max. 10)
  PYLINT_MIN_SCORE: "9.00"
  # minimum code coverage (goal: 80%; max. 100%)
  COVERAGE_MIN_PERC: "68"
  # maximum code complexity (goal: <= 15; unbounded)
  COMPLEXITY_MAX_SCORE: "38"
  # minimum maintainability index (goal: >=20; max. 100)
  MAINTAINABILITY_MIN_INDEX: "10.62"
  SOURCE_DIRS: "qmi/"
  WORKFLOW_DIR: ".github/workflows"

jobs:
  on_push:

    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3
      - name: Set up Python-latest
        uses: actions/setup-python@v4
        with:
          # Take latest Python 3 version
          python-version: "3.x"
      - name: Install dependencies
        run: |
          sudo apt-get update -qy
          sudo apt-get install -y bc
          python3 --version
          pip install --upgrade pip
          pip install -e '.[dev]'
          pip install anybadge
      - name: setup git config
        run: |
          git config user.name "GitHub Actions Bot"
          git config user.mail "<>"
      - name: pylint
        run: |
          pip install pylint
          chmod a+x scripts/run_analysis_pylint.sh 
          SCORE=$( scripts/run_analysis_pylint.sh )
          echo $SCORE $PYLINT_MIN_SCORE
          echo $SCORE > pylint_score
          # bc evaluates to `1` if relation is true
          exit $( echo "$SCORE < $PYLINT_MIN_SCORE" | bc )
          anybadge -l pylint -v $SCORE -f $WORKFLOW_DIR/pylint.svg 2=red 4=orange 8=yellow 10=green
        continue-on-error: true
      - name: upload pylint test results
        uses: actions/upload-artifact@v3
        with:
          name: pylint-results
          path: pylint.log
        if: ${{ always() }}
      - name: commit pylint test badge
        run: |
          git add $WORKFLOW_DIR/pylint.svg
          git commit -m "testing commit pylint badge to main"
          git push origin main
      - name: mypy
        run: |
          pip install mypy
          mypy --namespace-packages $SOURCE_DIRS | tee mypy.log
        continue-on-error: true
      - name: upload mypy test results
        uses: actions/upload-artifact@v3
        with:
          name: mypy-results
          path: mypy.log
        if: ${{ always() }}
      - name: radon-cc
        run: |
          pip install radon
          chmod a+x scripts/run_analysis_cc.sh
          MAX_SCORE=$( scripts/run_analysis_cc.sh $SOURCE_DIRS )
          echo $MAX_SCORE $COMPLEXITY_MAX_SCORE
          echo $MAX_SCORE > cc_max_score
          # bc evaluates to `1` if relation is true
          exit $( echo "$MAX_SCORE > $COMPLEXITY_MAX_SCORE" | bc )
        continue-on-error: true
      - name: upload radon-cc results
        uses: actions/upload-artifact@v3
        with:
          name: radon-cc-results
          path: radon-cc.log
        if: ${{ always() }}
      - name: radon-mi
        run: |
          pip install radon
          chmod a+x scripts/run_analysis_mi.sh
          MIN_INDEX=$( scripts/run_analysis_mi.sh $SOURCE_DIRS )
          echo $MIN_INDEX $MAINTAINABILITY_MIN_INDEX
          echo $MIN_INDEX > mi_min_index
          exit $( echo "$MIN_INDEX < $MAINTAINABILITY_MIN_INDEX" | bc )  # bc evaluates to `1` if relation is true
        continue-on-error: true
      - name: upload radon-mi results
        uses: actions/upload-artifact@v3
        with:
          name: radon-mi-results
          path: radon-mi.log
        if: ${{ always() }}
      - name: coverage
        run: |
          pip install coverage
          chmod a+x scripts/run_unit_tests_with_coverage.sh
          scripts/run_unit_tests_with_coverage.sh $SOURCE_DIRS
          coverage report --show-missing --fail-under=$COVERAGE_MIN_PERC | tee coverage.log
          # coverage: '/^TOTAL.+?(\d+\%)$/'
      - name: upload coverage results
        uses: actions/upload-artifact@v3
        with:
          name: coverage-results
          path: coverage.log
        if: ${{ always() }}
      - name: unit-tests latest
        run: |
          pip install unittest-xml-reporting
          python -m xmlrunner --output-file testresults.xml discover --start-directory=tests --pattern="test_*.py"
      - name: upload unit-tests results
        uses: actions/upload-artifact@v3
        with:
          name: unit-test-results
          path: testresults.xml
        if: ${{ always() }}
